{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a7e546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set project root\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Manually set the path to the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7120ca05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Literal\n",
    "\n",
    "from src.pipeline.geometry import derive_metric_homography\n",
    "from src.data import Template, load_measurements_from_yaml\n",
    "from src.pipeline.matching import extract_features, match_descriptors, compute_homography\n",
    "from src.pipeline.geometry import recover_all_poses_from_homography, select_best_solution\n",
    "from src.utils import load_rgb\n",
    "from src.pipeline.calibration import CalibrationSimple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d227aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to data\n",
    "colmap_path = os.path.join(project_root, 'assets', 'colmap')\n",
    "images_dir = os.path.join(colmap_path, 'images')\n",
    "depth_maps_dir = os.path.join(colmap_path, 'depth_maps')\n",
    "corners_csv_path = os.path.join(colmap_path, 'book_corners_labels.csv')\n",
    "focal_lengths_path = os.path.join(colmap_path, 'focal_lengths.npy')\n",
    "\n",
    "# Load focal lengths estimations by DepthPro\n",
    "focal_lengths = np.load(focal_lengths_path, allow_pickle=True)\n",
    "\n",
    "# Load corner annotations\n",
    "corners_df = pd.read_csv(corners_csv_path)\n",
    "\n",
    "# Load template data\n",
    "data = load_measurements_from_yaml(\"../assets/measurements.yaml\")\n",
    "\n",
    "# Ground-truth focal length in pixels\n",
    "f_gt = 5152.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f889eb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_corners(filename: str) -> np.ndarray:\n",
    "    # Identify correct row in the df\n",
    "    row = corners_df[corners_df['image_name'] == filename].iloc[0]\n",
    "    \n",
    "    # Extract 2D corner coordinates (in image pixels)\n",
    "    corners = np.array([\n",
    "        [row['top_left_x'], row['top_left_y']],\n",
    "        [row['top_right_x'], row['top_right_y']], \n",
    "        [row['bottom_right_x'], row['bottom_right_y']],\n",
    "        [row['bottom_left_x'], row['bottom_left_y']]\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "    return corners\n",
    "\n",
    "def compute_pose_from_corners(\n",
    "    corners: np.ndarray,\n",
    "    K: np.ndarray,\n",
    "    w_m: float,\n",
    "    h_m: float\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    # Define book corners in book's local coordinate system\n",
    "    corners_3d = np.array([\n",
    "        [0, 0, 0],\n",
    "        [w_m, 0, 0],\n",
    "        [w_m, h_m, 0],\n",
    "        [0, h_m, 0]\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    # Solve PnP to get camera pose relative to book\n",
    "    success, rvec, tvec = cv2.solvePnP(corners_3d, corners, K, None)\n",
    "    \n",
    "    if not success:\n",
    "        print(\"PnP solving failed!\")\n",
    "        return None, None\n",
    "\n",
    "    return rvec, tvec\n",
    "\n",
    "def compute_pose_ground_truth(pose: tuple[np.ndarray, np.ndarray]) -> tuple[float, np.ndarray]:\n",
    "    rvec, tvec = pose\n",
    "    R, _ = cv2.Rodrigues(rvec)\n",
    "    return np.linalg.norm(tvec), R[:, 2]\n",
    "\n",
    "def template_match(\n",
    "    scene: np.ndarray,\n",
    "    templates: list[Template],\n",
    "    extract_method: Literal['SIFT', 'ORB'] = 'SIFT',\n",
    "    match_method: Literal['BF', 'FLANN'] = 'BF',\n",
    "    min_match_count: int = 10,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Perform multi-template matching on a scene image for the given templates.\n",
    "\n",
    "    Args:\n",
    "        scene (np.ndarray): The scene image.\n",
    "        templates (list[Template]): List of template objects to match against the scene.\n",
    "        extract_method (Literal['SIFT', 'ORB']): Feature extraction method.\n",
    "        match_method (Literal['BF', 'FLANN']): Feature matching method.\n",
    "        min_match_count (int): Minimum number of matches required to consider a valid match.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The image size of the scene.\n",
    "        dict: A dictionary containing, indexed by template id. For each template:\n",
    "            - 'homography': The computed homography matrix.\n",
    "            - 'error': The reprojection error.\n",
    "    \"\"\"\n",
    "    # Initialize the results dictionary\n",
    "    results = {}\n",
    "\n",
    "    # Extract its features and descriptors\n",
    "    scene_keypoints, scene_descriptors = extract_features(scene, method=extract_method, max_features=20000)\n",
    "\n",
    "    # Drawing\n",
    "    scene_image_copy = scene.copy()\n",
    "\n",
    "    # Iterate over each template\n",
    "    for template in templates:\n",
    "        # Load the template image\n",
    "        template_image = load_rgb(os.path.join(project_root, template.path))\n",
    "\n",
    "        # Extract features and descriptors from the template\n",
    "        template_keypoints, template_descriptors = extract_features(template_image, method=extract_method)\n",
    "\n",
    "        # Match the descriptors between the scene and the template\n",
    "        matches = match_descriptors(template_descriptors, scene_descriptors, method=match_method)\n",
    "\n",
    "        # Check if enough matches are found\n",
    "        if len(matches) <= min_match_count:\n",
    "            print(f\"Not enough matches found for template {template.id}.\")\n",
    "            continue\n",
    "            \n",
    "        # Compute the homography\n",
    "        H_px, mask, error = compute_homography(template_keypoints, scene_keypoints, matches)\n",
    "\n",
    "        # Derive the metric homography\n",
    "        H_metric = derive_metric_homography(\n",
    "            H_px=H_px,\n",
    "            template_size_px=template_image.shape[:2],\n",
    "            template_size_metric=(template.height, template.width),\n",
    "        )\n",
    "\n",
    "        # Remove the scene keypoints that were used as inliers in the homography computation\n",
    "        inlier_indices = set()\n",
    "        for i, match in enumerate(matches):\n",
    "            if mask[i] == 1:  # This match was an inlier\n",
    "                inlier_indices.add(match.queryIdx)  # queryIdx is the scene keypoint index\n",
    "\n",
    "        # Keep only the keypoints that weren't used as inliers\n",
    "        remaining_indices = [i for i in range(len(scene_keypoints)) if i not in inlier_indices]\n",
    "        scene_keypoints = [scene_keypoints[i] for i in remaining_indices]\n",
    "        scene_descriptors = scene_descriptors[remaining_indices]\n",
    "\n",
    "        # Plot template contour on scene image\n",
    "        template_h, template_w = template_image.shape[:2]\n",
    "        template_corners = np.float32([[0, 0], [template_w, 0], [template_w, template_h], [0, template_h]]).reshape(-1, 1, 2)\n",
    "        scene_corners = cv2.perspectiveTransform(template_corners, H_px)\n",
    "\n",
    "        cv2.polylines(scene_image_copy, [np.int32(scene_corners)], True, (0, 255, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "        # Store the results\n",
    "        results[template.id] = {\n",
    "            'homography': H_metric,\n",
    "            'error': error\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "def calibrate_camera(\n",
    "    homographies: list[np.ndarray],\n",
    "    image_size: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calibrate the camera using a set of homographies.\n",
    "    For simplicity, only the focal length is estimated, based on the following assumptions:\n",
    "    - zero skew\n",
    "    - principal point at the image center\n",
    "    - square pixels (fx = fy = f)\n",
    "\n",
    "    Args:\n",
    "        homographies (list[np.ndarray]): List of homographies.\n",
    "        image_size (tuple[int, int]): Size of the image (height, width).\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Estimated intrinsic camera matrix (3x3).\n",
    "    \"\"\"\n",
    "    # Compute the principal point\n",
    "    cx, cy = image_size[1] / 2, image_size[0] / 2\n",
    "\n",
    "    # Initialize the calibration object\n",
    "    calibration = CalibrationSimple()\n",
    "\n",
    "    # Calibrate the camera\n",
    "    calibration.add_homographies(homographies)\n",
    "    return calibration.calibrate(principal_point=(cx, cy))\n",
    "\n",
    "def refine_calibration(\n",
    "    templates: list[Template],\n",
    "    homographies: list[np.ndarray],\n",
    "    image_size: np.ndarray,\n",
    "    K_init: np.ndarray,\n",
    "    resolution: int = 20,\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Refine the camera intrinsics and estimate radial distortion parameters (k1, k2).\n",
    "\n",
    "    Args:\n",
    "        templates (list[Template]): List of template objects containing metric dimensions.\n",
    "        homographies (list[np.ndarray]): List of homographies for the scene.\n",
    "        image_size (np.ndarray): Size of the image (width, height).\n",
    "        K_init (np.ndarray): Initial intrinsic matrix (3x3).\n",
    "        resolution (int): Resolution for the grid of points used for each template.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Refined intrinsic matrix (3x3) and radial distortion parameters (1D array).\n",
    "    \"\"\"\n",
    "    # Define the world points and the corresponding image points for each template\n",
    "    object_points = []\n",
    "    image_points = []\n",
    "    for template, H in zip(templates, homographies):\n",
    "        # Get template metric dimensions\n",
    "        w, h = template.width, template.height\n",
    "\n",
    "        # Define grid points on the template\n",
    "        x = np.linspace(0, w, resolution)\n",
    "        y = np.linspace(0, h, resolution)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "\n",
    "        # Create world points\n",
    "        object_points_3d = np.array([\n",
    "            [x, y, 0] for x, y, in zip(X.flatten(), Y.flatten())\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "        # Create image points\n",
    "        image_points_2d = cv2.perspectiveTransform(\n",
    "            object_points_3d[:, :2].reshape(-1, 1, 2), H\n",
    "        ).reshape(-1, 2)\n",
    "\n",
    "        # Add these points to the lists\n",
    "        object_points.append(object_points_3d)\n",
    "        image_points.append(image_points_2d)\n",
    "\n",
    "    # Initialize the distortion coefficients to zero\n",
    "    dist_coeffs_init = np.zeros(5, dtype=np.float32)\n",
    "\n",
    "    # Define the flags for the optimization\n",
    "    flags = (\n",
    "        cv2.CALIB_USE_INTRINSIC_GUESS |\n",
    "        cv2.CALIB_FIX_PRINCIPAL_POINT |\n",
    "        cv2.CALIB_FIX_ASPECT_RATIO |\n",
    "        cv2.CALIB_ZERO_TANGENT_DIST |\n",
    "        cv2.CALIB_FIX_K3 |\n",
    "        cv2.CALIB_FIX_K4 |\n",
    "        cv2.CALIB_FIX_K5 |\n",
    "        cv2.CALIB_FIX_K6\n",
    "    )\n",
    "\n",
    "    # Refine the intrinsic parameters and distortion coefficients\n",
    "    ret, K, dist_coeffs, rvecs, tvecs = cv2.calibrateCamera(\n",
    "        objectPoints=object_points,\n",
    "        imagePoints=image_points,\n",
    "        imageSize=image_size,\n",
    "        cameraMatrix=K_init,\n",
    "        distCoeffs=dist_coeffs_init,\n",
    "        flags=flags\n",
    "    )\n",
    "\n",
    "    if not ret:\n",
    "        raise RuntimeError(\"Camera calibration failed. Check the input data and parameters.\")\n",
    "    \n",
    "    # Return the refined intrinsic matrix and distortion coefficients\n",
    "    return K, dist_coeffs[:2]\n",
    "\n",
    "def analyze_scene(\n",
    "    templates: list[Template],\n",
    "    homographies: list[np.ndarray],\n",
    "    K: np.ndarray\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Analyze a scene by computing the distance from the camera to the center of each template.\n",
    "\n",
    "    Args:\n",
    "        templates (list[Template]): List of template objects containing metric dimensions.\n",
    "        homographies (list[np.ndarray]): List of homographies for the scene.\n",
    "        K (np.ndarray): Intrinsic camera matrix.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing, indexed by template id. For each template:\n",
    "            - the estimated distance\n",
    "            - the estimated normal to the template plane\n",
    "    \"\"\"\n",
    "    # Iterate over templates\n",
    "    results = {}\n",
    "    for template, H_metric in zip(templates, homographies):\n",
    "        # Get pose from homography\n",
    "        poses = recover_all_poses_from_homography(H_metric, K)\n",
    "        best_pose = select_best_solution(poses)\n",
    "        \n",
    "        if best_pose is None:\n",
    "            continue\n",
    "            \n",
    "        R, t, _ = best_pose\n",
    "\n",
    "        results[template.id] = {\n",
    "            'd': np.linalg.norm(t) / 1000,  # Convert to meters\n",
    "            'n': R[:, 2]\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "def pipeline_results(image: np.ndarray) -> tuple[float, float, np.ndarray]:\n",
    "    # Load the template\n",
    "    template_id = \"T5\"\n",
    "    templates = [data.get_template(template_id)]\n",
    "\n",
    "    # Perform template matching\n",
    "    results = template_match(image, templates)\n",
    "\n",
    "    # Extract homographies from results\n",
    "    homographies = [result['homography'] for result in results.values()]\n",
    "\n",
    "    # Calibrate the camera using the homographies\n",
    "    K_init = calibrate_camera(homographies=homographies, image_size=image.shape[:2])\n",
    "\n",
    "    # Refine the calibration using the templates and homographies\n",
    "    K_refined, _ = refine_calibration(\n",
    "        templates=templates,\n",
    "        homographies=homographies,\n",
    "        image_size=image.shape[:2],\n",
    "        K_init=K_init\n",
    "    )\n",
    "\n",
    "    # Analyze the scene\n",
    "    results = analyze_scene(\n",
    "        templates=templates,\n",
    "        homographies=homographies,\n",
    "        K=K_refined\n",
    "    )[template_id]\n",
    "\n",
    "    return K_refined[0, 0], results['d'], results['n']\n",
    "\n",
    "def get_plane_normal_from_corners(corners: np.ndarray, depth_map: np.ndarray, focal_length: float) -> np.ndarray:\n",
    "    # Camera parameters\n",
    "    h, w = depth_map.shape[:2]\n",
    "    cx = w / 2\n",
    "    cy = h / 2\n",
    "    \n",
    "    # Convert 2D corners to 3D using depth\n",
    "    corners_3d = []\n",
    "    for x, y in corners:\n",
    "        depth = depth_map[int(y), int(x)]\n",
    "        # Convert to 3D camera coordinates\n",
    "        x_3d = (x - cx) * depth / focal_length\n",
    "        y_3d = (y - cy) * depth / focal_length\n",
    "        z_3d = depth\n",
    "        corners_3d.append([x_3d, y_3d, z_3d])\n",
    "    \n",
    "    corners_3d = np.array(corners_3d)\n",
    "\n",
    "    \n",
    "    # Fit plane using SVD\n",
    "    centroid = np.mean(corners_3d, axis=0)\n",
    "    centered_points = corners_3d - centroid\n",
    "    _, _, Vt = np.linalg.svd(centered_points)\n",
    "    normal = Vt[-1]  # Last row of Vt is the normal vector\n",
    "    \n",
    "    return normal\n",
    "\n",
    "def depth_pro_results(corners: np.ndarray, depth_map: np.ndarray, focal_length: float) -> tuple[float, float, np.ndarray]:\n",
    "    depth = depth_map[int(corners[0][1]), int(corners[0][0])]\n",
    "    normal = get_plane_normal_from_corners(corners, depth_map, focal_length)\n",
    "    return depth, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d0006f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare():\n",
    "    # Instantiate results\n",
    "    f_comparison = {}\n",
    "    distance_comparison = {}\n",
    "    normal_comparison = {}\n",
    "\n",
    "    # Loop through each image\n",
    "    filenames = glob.glob(os.path.join(images_dir, '*.jpg'))\n",
    "    for i, filename in enumerate(sorted(filenames)):\n",
    "        image_name = os.path.basename(filename)\n",
    "        print(f\"[{i + 1}/{len(filenames)}] {image_name}\")\n",
    "\n",
    "        # Load image and depth map\n",
    "        image = load_rgb(filename)\n",
    "        depth_path = os.path.join(depth_maps_dir, image_name.replace('.jpg', '_map.npy'))\n",
    "        depth_map = np.load(depth_path).T\n",
    "\n",
    "        # Compute ground-truth K\n",
    "        h, w = image.shape[:2]\n",
    "        K_gt = np.array([\n",
    "            [f_gt, 0, w / 2],\n",
    "            [0, f_gt, h / 2],\n",
    "            [0, 0, 1]\n",
    "        ])\n",
    "\n",
    "        # Compute ground-truth camera pose from annotated corners\n",
    "        corners = extract_corners(image_name)\n",
    "        gt_pose = compute_pose_from_corners(corners, K_gt, w_m=0.173, h_m=0.26)\n",
    "\n",
    "        # Ground-truth distance and normal\n",
    "        d_gt, n_gt = compute_pose_ground_truth(gt_pose)\n",
    "\n",
    "        # Pipeline results\n",
    "        f_pp, d_pp, n_pp = pipeline_results(image)\n",
    "\n",
    "        # DepthPro results\n",
    "        f_dp = focal_lengths.item()[image_name]\n",
    "        d_dp, n_dp = depth_pro_results(corners, depth_map, f_dp)\n",
    "\n",
    "        # Store results\n",
    "        f_comparison[image_name] = {\n",
    "            'pipeline': f_pp,\n",
    "            'depth-pro': f_dp,\n",
    "            'gt': f_gt,\n",
    "        }\n",
    "        distance_comparison[image_name] = {\n",
    "            'pipeline': d_pp,\n",
    "            'depth-pro': d_dp,\n",
    "            'gt': d_gt,\n",
    "        }\n",
    "        normal_comparison[image_name] = {\n",
    "            'pipeline': n_pp,\n",
    "            'depth-pro': n_dp,\n",
    "            'gt': n_gt,\n",
    "        }\n",
    "\n",
    "    return f_comparison, distance_comparison, normal_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0c15bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/50] IMG_8222.jpg\n",
      "[2/50] IMG_8223.jpg\n",
      "[3/50] IMG_8224.jpg\n",
      "[4/50] IMG_8225.jpg\n",
      "[5/50] IMG_8226.jpg\n",
      "[6/50] IMG_8227.jpg\n",
      "[7/50] IMG_8228.jpg\n",
      "[8/50] IMG_8229.jpg\n",
      "[9/50] IMG_8230.jpg\n",
      "[10/50] IMG_8231.jpg\n",
      "[11/50] IMG_8232.jpg\n",
      "[12/50] IMG_8233.jpg\n",
      "[13/50] IMG_8234.jpg\n",
      "[14/50] IMG_8235.jpg\n",
      "[15/50] IMG_8236.jpg\n",
      "[16/50] IMG_8237.jpg\n",
      "[17/50] IMG_8238.jpg\n",
      "[18/50] IMG_8239.jpg\n",
      "[19/50] IMG_8240.jpg\n",
      "[20/50] IMG_8241.jpg\n",
      "[21/50] IMG_8242.jpg\n",
      "[22/50] IMG_8243.jpg\n",
      "[23/50] IMG_8244.jpg\n",
      "[24/50] IMG_8245.jpg\n",
      "[25/50] IMG_8246.jpg\n",
      "[26/50] IMG_8247.jpg\n",
      "[27/50] IMG_8248.jpg\n",
      "[28/50] IMG_8249.jpg\n",
      "[29/50] IMG_8250.jpg\n",
      "[30/50] IMG_8251.jpg\n",
      "[31/50] IMG_8252.jpg\n",
      "[32/50] IMG_8253.jpg\n",
      "[33/50] IMG_8254.jpg\n",
      "[34/50] IMG_8255.jpg\n",
      "[35/50] IMG_8256.jpg\n",
      "[36/50] IMG_8257.jpg\n",
      "[37/50] IMG_8258.jpg\n",
      "[38/50] IMG_8259.jpg\n",
      "[39/50] IMG_8260.jpg\n",
      "[40/50] IMG_8261.jpg\n",
      "[41/50] IMG_8262.jpg\n",
      "[42/50] IMG_8263.jpg\n",
      "[43/50] IMG_8264.jpg\n",
      "[44/50] IMG_8265.jpg\n",
      "[45/50] IMG_8266.jpg\n",
      "[46/50] IMG_8268.jpg\n",
      "[47/50] IMG_8269.jpg\n",
      "[48/50] IMG_8270.jpg\n",
      "[49/50] IMG_8271.jpg\n",
      "[50/50] IMG_8272.jpg\n"
     ]
    }
   ],
   "source": [
    "f_comp, d_comp, n_comp = compare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5577dd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        if isinstance(obj, (np.float64, np.float32, np.int64, np.int32)):\n",
    "            return float(obj)\n",
    "        return super().default(obj)\n",
    "\n",
    "# Save all three dictionaries\n",
    "data_to_save = {\n",
    "    'f_comp': f_comp,\n",
    "    'd_comp': d_comp,\n",
    "    'n_comp': n_comp\n",
    "}\n",
    "\n",
    "output_path = os.path.join(colmap_path, 'comparisons_v2.json')\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(data_to_save, f, cls=NumpyEncoder, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "single-view-3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
