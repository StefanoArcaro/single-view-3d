{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "542703c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set project root\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Manually set the path to the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fecd1f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from src.geometry import (\n",
    "    compute_distance_from_homography,\n",
    "    derive_metric_homography,\n",
    ")\n",
    "from src.matching import template_match\n",
    "from src.measurement_data import Template, load_measurements_from_yaml\n",
    "from src.utils import load_calibration_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dc4eaf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_all_poses_from_homography(H: np.ndarray, K: np.ndarray) -> list:\n",
    "    \"\"\"\n",
    "    Recover all 4 possible poses from homography decomposition.\n",
    "    Returns list of (R, t, n) tuples where n is the plane normal.\n",
    "    \"\"\"\n",
    "    # Remove camera intrinsics\n",
    "    H_norm = np.linalg.inv(K) @ H\n",
    "    \n",
    "    # Extract and normalize\n",
    "    r1 = H_norm[:, 0]\n",
    "    r2 = H_norm[:, 1] \n",
    "    t = H_norm[:, 2]\n",
    "    \n",
    "    # Two possible normalizations (+ and -)\n",
    "    scale = np.linalg.norm(r1)\n",
    "    \n",
    "    solutions = []\n",
    "    \n",
    "    for sign in [1, -1]:\n",
    "        r1_scaled = sign * r1 / scale\n",
    "        r2_scaled = sign * r2 / scale\n",
    "        t_scaled = sign * t / scale\n",
    "        \n",
    "        # Orthogonalize\n",
    "        # r2_ortho = r2_scaled - np.dot(r2_scaled, r1_scaled) * r1_scaled\n",
    "        # r2_ortho /= np.linalg.norm(r2_ortho)\n",
    "        r3 = np.cross(r1_scaled, r2_scaled)\n",
    "        \n",
    "        # Build rotation matrix\n",
    "        R_approx = np.column_stack((r1_scaled, r2_scaled, r3))\n",
    "        \n",
    "        # Project to SO(3)\n",
    "        U, _, Vt = np.linalg.svd(R_approx)\n",
    "        if np.linalg.det(U @ Vt) < 0:\n",
    "            U[:, -1] *= -1\n",
    "        R = U @ Vt\n",
    "        \n",
    "        # Compute plane normal (third row of R)\n",
    "        n = R[2, :]\n",
    "        \n",
    "        solutions.append((R, t_scaled, n))\n",
    "        \n",
    "        # Also add the solution with flipped normal\n",
    "        solutions.append((R, t_scaled, -n))\n",
    "    \n",
    "    return solutions\n",
    "\n",
    "def select_best_solution(solutions: list, expected_z_positive=True) -> tuple:\n",
    "    \"\"\"\n",
    "    Select the most reasonable solution based on constraints.\n",
    "    For a template in front of camera, we expect positive Z and small X,Y.\n",
    "    \"\"\"\n",
    "    best_solution = None\n",
    "    best_score = float('inf')\n",
    "    \n",
    "    for R, t, n in solutions:\n",
    "        # Score based on:\n",
    "        # 1. Z should be positive and dominant\n",
    "        # 2. X, Y should be small relative to Z\n",
    "        if expected_z_positive and t[2] <= 0:\n",
    "            continue\n",
    "            \n",
    "        score = (abs(t[0]) + abs(t[1])) / abs(t[2])  # Want this to be small\n",
    "        \n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_solution = (R, t, n)\n",
    "    \n",
    "    return best_solution\n",
    "\n",
    "# Usage:\n",
    "# solutions = recover_all_poses_from_homography(H, K)\n",
    "# R, t, n = select_best_solution(solutions)\n",
    "# t_scaled = t * 490 / np.linalg.norm(t)  # Scale to correct distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e70f4813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geometry import recover_pose_from_homography\n",
    "\n",
    "\n",
    "class WebVisualizer:\n",
    "    \"\"\"\n",
    "    A lightweight visualizer for 3D poses of planar templates and camera position,\n",
    "    generating an HTML file with Three.js for interactive viewing.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the web visualizer.\n",
    "\n",
    "        Args:\n",
    "            template_size (tuple): (width, height) of each planar template in world units.\n",
    "        \"\"\"\n",
    "\n",
    "        self.meshes = []       # List of mesh dicts for templates\n",
    "        self.lines = []        # List of line-set dicts for camera frustum & axes\n",
    "\n",
    "    def create_template_quad(\n",
    "        self,\n",
    "        R: np.ndarray,\n",
    "        t: np.ndarray,\n",
    "        width: float,\n",
    "        height: float,\n",
    "        color: tuple[float, float, float] = (0.7, 0.7, 0.9),\n",
    "        texture_path: str | None = None\n",
    "    ) -> dict:\n",
    "        \"\"\"\n",
    "        Create a mesh dict representing a template quad at pose (R, t).\n",
    "\n",
    "        Args:\n",
    "            R (np.ndarray): 3x3 rotation matrix (camera to template).\n",
    "            t (np.ndarray): 3-element translation vector.\n",
    "            width (float): Width of the template in world units.\n",
    "            height (float): Height of the template in world units.\n",
    "            color (tuple): RGB tuple for face color.\n",
    "            texture_path (str): Optional path to texture image.\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'vertices', 'triangles', 'color', and optional 'texture'.\n",
    "        \"\"\"\n",
    "        # Local quad vertices centered at origin\n",
    "        # local = np.array([\n",
    "        #     [-width / 2, -height / 2, 0],\n",
    "        #     [ width / 2, -height / 2, 0],\n",
    "        #     [ width / 2,  height / 2, 0],\n",
    "        #     [-width / 2,  height / 2, 0]\n",
    "        # ])  # shape (4,3)\n",
    "\n",
    "        local = np.array([\n",
    "            [   0,    0, 0],\n",
    "            [ width,  0, 0],\n",
    "            [ width, -height, 0],\n",
    "            [   0, -height, 0]\n",
    "        ])\n",
    "\n",
    "        # Convert to right-handed coordinate system\n",
    "        # local[:, 1] *= -1  # Flip Y axis\n",
    "\n",
    "        # Transform to world coords\n",
    "        verts = (R @ local.T).T + np.asarray(t).reshape(1, 3)\n",
    "\n",
    "        mesh = {\n",
    "            'name': 'template',\n",
    "            'vertices': verts.tolist(),\n",
    "            'triangles': [[0,2,1], [0,3,2]],\n",
    "            'color': list(color)\n",
    "        }\n",
    "        if texture_path:\n",
    "            mesh['texture'] = texture_path\n",
    "\n",
    "        return mesh\n",
    "\n",
    "    def create_camera_frustum(self, focal_length: float = 1.0, image_size: tuple = (640, 480), scale: float = 0.3, color: tuple = (1.0, 0.0, 0.0)):\n",
    "        \"\"\"\n",
    "        Create a line-set dict representing the camera frustum.\n",
    "\n",
    "        Args:\n",
    "            focal_length (float): focal length in pixels.\n",
    "            image_size (tuple): (width, height) in pixels.\n",
    "            scale (float): overall scale for near/far planes.\n",
    "            color (tuple): RGB tuple for line color.\n",
    "\n",
    "        Returns:\n",
    "            Dict with 'points', 'lines', 'color'.\n",
    "        \"\"\"\n",
    "        w, h = image_size\n",
    "\n",
    "        # Define near and far planes based on focal length and scale\n",
    "        near, far = 0.1 * scale, 490.0 * scale\n",
    "        near_x = near * (w / 2) / focal_length\n",
    "        near_y = near * (h / 2) / focal_length\n",
    "        far_x  = far * (w / 2) / focal_length\n",
    "        far_y  = far * (h / 2) / focal_length\n",
    "\n",
    "        # Define frustum points and connecting lines\n",
    "        points = [\n",
    "            [0, 0, 0],\n",
    "            [-near_x, -near_y, -near], [near_x, -near_y, -near],\n",
    "            [near_x, near_y, -near], [-near_x, near_y, -near],\n",
    "            [-far_x, -far_y, -far], [far_x, -far_y, -far],\n",
    "            [far_x, far_y, -far], [ -far_x, far_y, -far]\n",
    "        ]\n",
    "\n",
    "        lines = [\n",
    "            [0, 1], [0, 2], [0, 3], [0, 4],\n",
    "            [1, 2], [2, 3], [3, 4], [4, 1],\n",
    "            [1, 5], [2, 6], [3, 7], [4, 8],\n",
    "            [5, 6], [6, 7], [7, 8], [8, 5]\n",
    "        ]\n",
    "\n",
    "        return {'name': 'camera_frustum', 'points': points, 'lines': lines, 'color': list(color)}\n",
    "    \n",
    "    def add_scene_results(\n",
    "        self,\n",
    "        scene_results: dict,\n",
    "        K: np.ndarray,\n",
    "        template_metadata: dict[str, Template]\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Turn your analyze_scene output into meshes.\n",
    "\n",
    "        Args:\n",
    "            scene_results (dict): results of scene analysis.\n",
    "            K (np.ndarray): camera intrinsics matrix\n",
    "            template_metadata (Template): Template instance containing width, height, and texture paths.\n",
    "        \"\"\"\n",
    "        # Create a mesh for each template found in the scene\n",
    "        for templ_id, info in scene_results.items():\n",
    "            H = np.array(info['homography'])\n",
    "\n",
    "            # Get the template metadata\n",
    "            template = template_metadata[templ_id]\n",
    "            width = template.width\n",
    "            height = template.height\n",
    "            texture_path = os.path.join('..', template.path)\n",
    "\n",
    "            # Recover the camera pose from the homography (camera w.r.t. template)\n",
    "            # num_solutions, Rs, ts, ns = cv2.decomposeHomographyMat(H, K)\n",
    "\n",
    "            # solution_to_test = 0\n",
    "            # R = Rs[solution_to_test]\n",
    "            # t = ts[solution_to_test]\n",
    "\n",
    "            # R_c, t_c, _ = select_best_solution(\n",
    "            #     recover_all_poses_from_homography(H, K),\n",
    "            #     expected_z_positive=True\n",
    "            # )\n",
    "            R, t = recover_pose_from_homography(H, K)\n",
    "\n",
    "            print(t)\n",
    "            print(np.linalg.norm(t))\n",
    "            print()\n",
    "\n",
    "            # Change coordinate system to template w.r.t. camera\n",
    "            R = R.T\n",
    "            t = R @ t\n",
    "\n",
    "            # # Flip Y and Z axes\n",
    "            # S = np.diag([1, -1, -1])  \n",
    "            # R = S @ R\n",
    "            # t = S @ t\n",
    "\n",
    "            # print(t)\n",
    "            # print(np.linalg.norm(t))\n",
    "            # print()\n",
    "\n",
    "            # t *= info['distance_true'] # TODO remember that the distance should be to the template origin, not the center\n",
    "\n",
    "            # print(t)\n",
    "            # print(np.linalg.norm(t))\n",
    "            # print()\n",
    "            t[2] *= -1\n",
    "            # t *= 0\n",
    "            # t[1] -= height\n",
    "\n",
    "            # Create the mesh for this template\n",
    "            scale = 1\n",
    "            mesh = self.create_template_quad(R, t / scale, width / scale, height / scale, texture_path=texture_path)\n",
    "            self.meshes.append(mesh)\n",
    "\n",
    "    def visualize(self, camera_params: dict = None, filename: str = 'template_visualization.html'):\n",
    "        \"\"\"\n",
    "        Generate the HTML file with Three.js embedding of meshes and lines.\n",
    "\n",
    "        Args:\n",
    "            camera_params (dict): dict with 'focal_length', 'image_size', 'scale'.\n",
    "            filename (str): output HTML file path. Defaults to 'template_visualization.html'.\n",
    "        \"\"\"\n",
    "        if camera_params is None:\n",
    "            camera_params = {'focal_length': 500.0, 'image_size': (640, 480), 'scale': 0.5}\n",
    "        frustum = self.create_camera_frustum(**camera_params)\n",
    "        self.lines.append(frustum)\n",
    "\n",
    "        # Prepare JSON data\n",
    "        html = self._generate_html(self.meshes, self.lines)\n",
    "        Path(filename).write_text(html)\n",
    "        print(f\"HTML visualization saved to {filename}\")\n",
    "\n",
    "    def _generate_html(self, meshes: list[dict], lines: list[dict]) -> str:\n",
    "        \"\"\"\n",
    "        Inject meshes and lines JSON into the HTML template.\n",
    "\n",
    "        Args:\n",
    "            meshes: list of mesh dicts.\n",
    "            lines: list of line-set dicts.\n",
    "\n",
    "        Returns:\n",
    "            Complete HTML content as a string.\n",
    "        \"\"\"\n",
    "        tpl_path = Path(os.path.join(project_root, 'assets', 'visualization_template.html.tpl'))\n",
    "        tpl = tpl_path.read_text()\n",
    "        return tpl.replace('{ meshes_json }', json.dumps(meshes)) \\\n",
    "                  .replace('{ lines_json }', json.dumps(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c4f6a4",
   "metadata": {},
   "source": [
    "## **Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4bca8324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load measurement data\n",
    "data = load_measurements_from_yaml(\"../assets/measurements.yaml\")\n",
    "\n",
    "# Load camera calibration\n",
    "K, dist_coeffs, image_size = load_calibration_json(\"../assets/camera_calibration.json\")\n",
    "\n",
    "scenes = data.get_all_scenes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "62716dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_scene(scene_id, scenes, K):\n",
    "    \"\"\"\n",
    "    This function analyzes a scene by executing the following steps:\n",
    "\n",
    "    1. Load the scene and the corresponding templates.\n",
    "    2. For each template, perform template matching against the scene image.\n",
    "    3. Compute the homography and recover the camera pose.\n",
    "    4. Compute the distance from the center of each template to the camera.\n",
    "    5. Return the results including the template ID, homography, camera pose, and distance.\n",
    "    \"\"\"\n",
    "    # Load scene and templates\n",
    "    scene = data.get_scene(scene_id)\n",
    "    templates = [data.get_template(t_id) for t_id in scenes[scene_id]]\n",
    "\n",
    "    # Iterate over templates\n",
    "    results = {}\n",
    "    for template in templates:\n",
    "        scene_path = os.path.join(project_root, scene.path)\n",
    "        template_path = os.path.join(project_root, template.path)\n",
    "\n",
    "        # Compute pixel-pixel homography\n",
    "        H, mask, t_shape, reprojection_error = template_match(template_path, scene_path, extract_method='SIFT', match_method='BF', plot=False)\n",
    "\n",
    "        template_size_px = plt.imread(template_path).shape[:2]\n",
    "\n",
    "        # Derive the metric-pixel homography\n",
    "        H_metric = derive_metric_homography(\n",
    "            H_px=H,\n",
    "            template_size_px=template_size_px,\n",
    "            template_size_metric=(template.height, template.width)\n",
    "        )\n",
    "\n",
    "        # Template center point\n",
    "        template_center_mm = np.array([template.width / 2, template.height / 2])\n",
    "\n",
    "        # Compute the distance from the camera to the template center\n",
    "        distance_pred = compute_distance_from_homography(\n",
    "            H_mm2img=H_metric,\n",
    "            K=K,\n",
    "            point_mm=template_center_mm\n",
    "        )\n",
    "\n",
    "        # True distance and error\n",
    "        distance_true = scene.get_distance('Camera', template.id).distance\n",
    "        error = np.abs(distance_pred - distance_true)\n",
    "        error_percent = (error / distance_true) * 100\n",
    "\n",
    "        results[template.id] = {\n",
    "            'homography': H_metric.tolist(),\n",
    "            'distance_pred': distance_pred,\n",
    "            'distance_true': distance_true,\n",
    "            'error': error,\n",
    "            'error_percent': error_percent,\n",
    "        }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a81b4820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze scene\n",
    "scene_id = 'S3'\n",
    "results = analyze_scene(scene_id, scenes, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5c521d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 140.90130492 -121.72958992  399.38370056]\n",
      "440.6570220305919\n",
      "\n",
      "[-125.61693581  -23.09284914  294.28194396]\n",
      "320.8032992166972\n",
      "\n",
      "HTML visualization saved to template_visualization.html\n"
     ]
    }
   ],
   "source": [
    "# Create the visualizer\n",
    "visualizer = WebVisualizer()\n",
    "\n",
    "# Load template metadata\n",
    "metadata = {t_id: data.get_template(t_id) for t_id in scenes[scene_id]}\n",
    "\n",
    "# Add results to the visualizer\n",
    "# TODO check recover pose function!\n",
    "visualizer.add_scene_results(\n",
    "    scene_results=results,\n",
    "    K=K,\n",
    "    template_metadata=metadata\n",
    ")\n",
    "\n",
    "# Visualize the results\n",
    "visualizer.visualize(\n",
    "    camera_params={'focal_length': K[0, 0], 'image_size': image_size, 'scale': 1},\n",
    "    filename='template_visualization.html'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
